# Deep Convolution Generative Adversarial Networks
GANs are a framework for teaching a DL model to capture the training data’s distribution so we can generate new data from that same distribution. GANs were invented by Ian Goodfellow in 2014 and first described in the paper [Generative Adversarial Nets](https://papers.nips.cc/paper/5423-generative-adversarial-nets.pdf). They are made of two distinct models, a generator and a discriminator. The job of the generator is to spawn ‘fake’ images that look like the training images. The job of the discriminator is to look at an image and output whether or not it is a real training image or a fake image from the generator. During training, the generator is constantly trying to outsmart the discriminator by generating better and better fakes, while the discriminator is working to become a better detective and correctly classify the real and fake images. The equilibrium of this game is when the generator is generating perfect fakes that look as if they came directly from the training data, and the discriminator is left to always guess at 50% confidence that the generator output is real or fake.

A DCGAN is a direct extension of the GAN described above, except that it explicitly uses convolutional and convolutional-transpose layers in the discriminator and generator, respectively. It was first described by Radford et. al. in the paper [Unsupervised Representation Learning With Deep Convolutional Generative Adversarial Networks](https://arxiv.org/pdf/1511.06434.pdf). The discriminator is made up of strided convolution layers, batch norm layers, and LeakyReLU activations. The input is a 3x64x64 input image and the output is a scalar probability that the input is from the real data distribution. The generator is comprised of convolutional-transpose layers, batch norm layers, and ReLU activations. The input is a latent vector, z, that is drawn from a standard normal distribution and the output is a 3x64x64 RGB image. The strided conv-transpose layers allow the latent vector to be transformed into a volume with the same shape as an image. In the paper, the authors also give some tips about how to setup the optimizers, how to calculate the loss functions, and how to initialize the model weights, all of which will be explained in the coming sections.
### Dataset: CIFAR-10
## Models
Gans is composed of a generator and a discriminator.
##### Generator
- It is made of five transposed convolution Layer. Each of these layers except the last one are followed by a batch normalisation layer and a ReLU layer. At the last layer, a tanh activation layer is applied as given in the DCGAN paper.
- A latent vector is passed into the Generator.
- A Fake Image of size (64 x 64 x 3) is Generated which is the input of the discriminator during the training process.
- A Batch Normalisation Layer should not be applied at the last Layer of the transpose convolution of the degenerator.
- No fully connected hidden layers are used

##### Discriminator
- It is made of five convolution layers. Each of these layers except the first and the last ones are followed by a batch Normalisation layer and a leaky ReLU layer(negative slope = 0.2).
- No Batch Normalisation should applied at the input layer.
- A Real Image from Training DataSet and A fake image generated by a Generator are the inputs to the Discriminator.
- At the Last Layer, A sigmoid activation function is used.
- No Hidden Layer is used. Its Final vector is mapped directly to a single output.

## Loss And Optimisers
- Binary Cross Entropy Loss :It is a Sigmoid activation plus a Cross-Entropy loss. Unlike Softmax loss it is independent for each vector component (class), meaning that the loss computed for every CNN output vector component is not affected by other component values. That’s why it is used for multi-label classification, were the insight of an element belonging to a certain class should not influence the decision for another class. It’s called Binary Cross-Entropy Loss because it sets up a binary classification problem between 
C′ = 2 classes for every class in C, as explained above. So when using this Loss, the formulation of Cross Entroypy Loss for binary problems is often used:  
ℓ(x,y) = L = { l1 , … , lN } ⊤ ,ln=−[ yn ⋅ logxn + (1 − yn ) ⋅ log( 1 − xn ) ]
- Real label defined as 1 and the Fake label as 0. These labels will be used when calculating the losses of Discriminator and Generator, and this is also the convention used in the original GAN paper. Finally, two separate optimizers are set up, one for Discriminator and one for Generator. As specified in the DCGAN paper, both are Adam optimizers with learning rate 0.0002 and Beta1 = 0.5. For keeping track of the generator’s learning progression, a fixed batch of latent vectors that are drawn from a Gaussian distribution (i.e. fixed_noise) will be generated . In the training loop, this fixed_noise will be periodically input into G, and over the iterations we will see images form out of the noise.